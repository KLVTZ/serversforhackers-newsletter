---
title: Load Balancing with HAProxy
topics: [HAProxy 1.5 on Ubuntu 14.04]
description: Setting up and using HAProxy 1.5 on Ubuntu 14.04
draft: true
---

# Load Balancing with HAProxy

While there are quite a few [good](http://nginx.com/resources/admin-guide/load-balancer/) [options](https://github.com/nodejitsu/node-http-proxy) for [load](https://f5.com/products/big-ip) [balancers](http://aws.amazon.com/elasticloadbalancing/), HAProxy has become a go-to Open Source solution.

It's used by many large companies, including GitHub, Stack Overflow, Reddit, Tumblr and Twitter.

HAProxy (High Availability Proxy)is able to handle a lot of traffic. Similar to Nginx, it uses a single-process, event-driven model. This uses a low amount of memory and enables HAProxy to handle a large number of concurrent requests.

Setting it up is pretty easy as well! We'll cover installing and setting up HAProxy to load balance between three sample NodeJS HTTP servers.

## Common Setups

In this example, I'll show using HAProxy to proxy requests between three NodeJS "web servers" (NodeJS applications using Node's HTTP library). This is just for example - in reality, you'll likely see HAProxy used to distribute requests across other "real" web servers, such as Nginx or Apache.

I try to give examples that are as good for production as they are for examples, but in this case, it's not overly important - from HAProxy's stand-point, an web server is a web server is a web server.

In a more "real" setup, web servers such as Apache or Nginx will stand between HAProxy and a web application. They'll typically either respond with static files or proxy requests they receive off to a Node, PHP, Ruby, Python, Go, Java or other dynamic application that might be in place. 

> You can see examples of Apache/Nginx proxying requets off to an application in the SFH editions/articles on [Apache](http://serversforhackers.com/articles/2014/05/05/apache-proxy-fcgi/) and [Nginx](http://serversforhackers.com/editions/2014/03/25/nginx/).

HAProxy can balance requests between any applicatino that can handle HTTP or even TCP requests. In this example, setting up three NodeJS web servers is just a convenient way to show load balancing between three web servers. How HAProxy sends requests to a web server or TCP end point doesn't end up changing how HAProxy works!

## Installation

We'll install the latest HAProxy (1.5.1 as of this writing) on Ubuntu 14.04. To do so, we can use the `ppa:vbernat/haproxy-1.5` repository, which will get us a recent stable release:

	sudo add-apt-repository -y ppa:vbernat/haproxy-1.5
	sudo apt-get update
	sudo apt-get install -y haproxy

> If you're missing the `add-apt-repository` command on Ubuntu 14.04, installing the `software-properties-common` package will retrieve it. This is different from previous Ubuntu's, who used the `python-software-properties` package to install `add-apt-repository`.

## Sample NodeJS Web Server

Now that HAProxy is installed, we need a few web servers to load balance between. To keep this example simple, we'll use a previously mentioned NodeJS application, which just opens up three HTTP listener on separate ports:

```
// File /srv/server.js
var http = require('http');

function serve(ip, port)
{
        http.createServer(function (req, res) {
            res.writeHead(200, {'Content-Type': 'text/plain'});
            res.write(JSON.stringify(req.headers));
            res.end("\nThere's no place like "+ip+":"+port+"\n");
        }).listen(port, ip);
        console.log('Server running at http://'+ip+':'+port+'/');
}

// Create three servers for
// the load balancer, listening on any
// network on the following three ports
serve('0.0.0.0', 9000);
serve('0.0.0.0', 9001);
serve('0.0.0.0', 9002);                    
```

We'll bounce between these three web servers with HAProxy.

## HAProxy Configuration

HAProxy configuration can be found at `/etc/haproxy/haproxy.cfg`. Here's what we'll likely see by default:

```
global
	log /dev/log    local0
	log /dev/log    local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin
	stats timeout 30s
	user haproxy
	group haproxy
	daemon
	
	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private
	
	# Default ciphers to use on SSL-enabled listening sockets.
	# For more information, see ciphers(1SSL).
	ssl-default-bind-ciphers kEECDH+aRSA+AES:kRSA+AES:+AES256:RC4-SHA:!kEDH:!LOW:!EXP:!MD5:!aNULL:!eNULL

defaults
	log     global
	mode    http
	option  httplog
	option  dontlognull
	timeout connect 5000
	timeout client  50000
	timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 400 /etc/haproxy/errors/403.http	
	errorfile 400 /etc/haproxy/errors/408.http
	errorfile 400 /etc/haproxy/errors/500.http
	errorfile 400 /etc/haproxy/errors/502.http
	errorfile 400 /etc/haproxy/errors/503.http
	errorfile 400 /etc/haproxy/errors/504.http
```

Here we have some global configuration, and then some defaults (which we can override as needed for each server setup).

Within `global`, I don't make any changes. Here we see that HAproxy is run as user/group `haproxy`, which is created during install. The master process is run as root - that process then uses `chroot` to separate HAproxy from other system areas for security (almost like running with its own container). It also sets itself as running as a daemon (in the background).

With `defaults`, we see some logging and timeout options. HAProxy can log all web requests, giving you the option to turn off access logs in each web node, or conversely, turning logs off at the load balancer while having them on within each web server (or any combination thereof). Where you want your logs to be generated/saved/aggregated is a decision you should make based on your needs. 

If you want to turn off logging regular (successful) HTTP requests within HAProxy, add the line `option dontlog-normal`. The [dontlog-normal directive](http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#4-option%20dontlog-normal) will tell HAProxy to only log error responses from the web nodes. Alternatively, you can simply separate error logs from the regular access logs via the [`option log-separate-errors`](http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#4.2-option%20log-separate-errors) option.

### Load Balancing Configuration

Next, we need to set some options within HAProxy:

* `frontend` - where HAProxy listens to connetions
* `backend` - Where HAPoxy sends incoming connections
* `stats` - Optionally, setup HAProxy web tool for monitoring the load balancer and its nodes

Here's an example frontend:

```
frontend localnodes
	bind *:80
	mode http
	default_backend nodes
```

This is a frontend, which I have named 'localnodes'. I named it 'localnodes' because the NodeJS app used to simulate three web servers is just being run locally. The name of the frontend is arbitrary.

* `bind *:80` - I've bound this frontend to all server network interfaces on port 80. HAProxy will listen on port 80 on each available network for new HTTP connections
* `mode http` - This is listening for HTTP connections. HAProxy can handle lower-level TCP connections as well, which is useful for load balancing things like MySQL read databases, if you setup database replication
* `default_backend nodes` - This frontend should use the backend named `nodes`, which we'll see next.

> TCP is "lower level" than HTTP. HTTP is actually built on top of TCP, so every HTTP connection uses TCP, but not every TCP connection is an HTTP request.

```
backend nodes
	mode http
	balance roundrobin
	option forwardfor
	http-request set-header X-Forwarded-Port %[dst_port]
	option httpchk HEAD / HTTP/1.1\r\nHost:localhost
	server web01 172.0.0.0:9000 check
	server web01 172.0.0.0:9001 check
	server web01 172.0.0.0:9002 check
```

This is the backend, which I've named "nodes". Again, this name is arbitrary. Let's go through the options:

* `mode http` - This will pass HTTP requests to the servers listed
* `balance roundrobin` - Use the [roundrobin](http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#4.2-balance) strategy for distributing load amonst the servers
* `option forwardfor` - Adds the `X-Forwarded-For` header so our applications can get the clients actualy IP address, instead of just the load balancers IP address
* `http-request set-header X-Forwarded-Port %[dst_port]` - We manually add the `X-Forwarded-Port` header so that our applications knows what port to use when redirecting/generating URLs. Note that we use the [`dst_port`](http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#7.3.3-dst_port) "destination port" variable, since that's from the point of view of the client, not HAProxy. The [`src_port`](http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#7.3.3-src_port) variable isn't used, it can and often is any random port number.
* `option httpchk HEAD / HTTP/1.1\r\nHost:localhost` - Set the healthcheck HAProxy uses to test if the web servers are still responding. If these fail to respond without error, the server is removed from HAProxy as one to load balance between. This heads a HEAD request with the `HTTP/1.1` and `Host` header set, which might be needed if your web server uses virtualhosts to detect which site to send traffic to
* `server web01 172.0.0.0:9000-2 check` - These three lines add a web [server](http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#4-server) for HAProxy to balance traffic between. It arbitrarily names each one `web01`-`web02`, set's their IP address and port, and adds the directive [`check`](http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#5.2-check) to tell HAProxy to health check the server

#### Load Balancing Algorithms

> Go over the various algo's available

### Start it!

Putting all those directives inside of the `/etc/haproxy/haproxy.cfg` file gives us a load balancer!

You start/restart start HAProxy with these settings:

	# You can reload if HAProxy is already started
	$ sudo service haproxy restart

Then start the Node server:

	$ node /srv/server.js

Then head to your servers IP address or hostname and see it balance traffic between the three Node servers:

```
{"host":"192.169.22.10","cache-control":"max-age=0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36","accept-encoding":"gzip,deflate,sdch","accept-language":"en-US,en;q=0.8","x-forwarded-proto":"80","x-forwarded-for":"172.17.42.1"}
There's no place like 0.0.0.0:9000

{"host":"192.169.22.10","cache-control":"max-age=0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36","accept-encoding":"gzip,deflate,sdch","accept-language":"en-US,en;q=0.8","x-forwarded-proto":"80","x-forwarded-for":"172.17.42.1"}
There's no place like 0.0.0.0:9001

{"host":"192.169.22.10","cache-control":"max-age=0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36","accept-encoding":"gzip,deflate,sdch","accept-language":"en-US,en;q=0.8","x-forwarded-proto":"80","x-forwarded-for":"172.17.42.1"}
There's no place like 0.0.0.0:9002
```

See how it round-robins between the three servers! We also have the `x-forwared-for` and `x-forwarded-port` headers available to us.



* Go through options
* Mention strategies for Load Balancing (Roundrobin vs...)
* Pay attention to x-forwarded options
	* [src_port](http://cbonte.github.io/haproxy-dconv/configuration-1.5.html#7.3.3-src_port) vs dst_port
* Usable Variables
